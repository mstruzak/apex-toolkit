{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bb55b17-7b5f-4aac-b298-95a9c4bc0925",
   "metadata": {},
   "source": [
    "# Generation of APEX Weather Files\n",
    "This notebook contains scripts to format climate data to .dly and .hly files for APEX from NASA POWER data. Follow the steps below to download NASA POWER data relevant to your project and load functions to generate new (or add to existing) APEX weather files. \n",
    "<br><br>\n",
    "The following functions are included:\n",
    "<br> - apex2dly: generate .dly file from NASA data (options to also generate .hly and .dly files and add spinup time)\n",
    "<br> - nasa2hly: generate .hly file from NASA data\n",
    "<br> - dly2hly: generate .hly file via uniform aggregated precip from existing .dly file\n",
    "<br> - dly2wp1: generate .wp1 file from existing .dly file (requires wxpm v.3020)\n",
    "<br> - add_spinup: duplicates first year of data 3 times to account for model spinup\n",
    "<br><br>\n",
    "<i>WARNING: MUST ENTER NEW STATIONS IN CORRESEPONDING .DAT INPUT FILES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf9413f",
   "metadata": {},
   "source": [
    "#### 1. Load necessary modules and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c908977-ff69-4363-ba10-0e6a86a368d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import datetime\n",
    "import shutil\n",
    "import subprocess\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e594286-c5ad-4465-8aa3-e0234beddbaa",
   "metadata": {},
   "source": [
    "#### 2. Load NASA data using API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598b5fbb",
   "metadata": {},
   "source": [
    "a. Set parameters for API search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c4d0955-afe0-4074-add6-857aa3a36adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **EDIT THIS BLOCK** to match site of interest\n",
    "longitude = '-80.0598'\n",
    "latitude = '40.443'\n",
    "start = '20130101'\n",
    "end = '20221231'\n",
    "elevation = '372.8'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197d5883",
   "metadata": {},
   "source": [
    "b. Get daily data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1f9680b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://power.larc.nasa.gov'\n",
    "endpoint = '/api/temporal/daily/point'\n",
    "\n",
    "# Define the query parameters\n",
    "params = {\n",
    "    'parameters': ['T2M_MAX,T2M_MIN,RH2M,ALLSKY_SFC_SW_DWN,PRECTOTCORR,WS10M'],\n",
    "    'community': 'AG',\n",
    "    'longitude': longitude,\n",
    "    'latitude': latitude,\n",
    "    'start': start,\n",
    "    'end': end,\n",
    "    'format': 'CSV'\n",
    "}\n",
    "\n",
    "# Make the GET request to the API\n",
    "response = requests.get(f\"{base_url}{endpoint}\", params=params)\n",
    "# \n",
    "dly_NASA = response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61363304",
   "metadata": {},
   "source": [
    "c. Get hourly data (optional):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c14810da",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://power.larc.nasa.gov'\n",
    "endpoint = '/api/temporal/hourly/point'\n",
    "\n",
    "# Define the query parameters\n",
    "params = {\n",
    "    'parameters': ['PRECTOTCORR'],\n",
    "    'community': 'AG',\n",
    "    'longitude': longitude,\n",
    "    'latitude': latitude,\n",
    "    'start': start,\n",
    "    'end': end,\n",
    "    'format': 'CSV',\n",
    "}\n",
    "\n",
    "# Make the GET request to the API\n",
    "response = requests.get(f\"{base_url}{endpoint}\", params=params)\n",
    "\n",
    "hly_NASA = response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69ba10f-769e-4836-804c-bdd413890acb",
   "metadata": {},
   "source": [
    "#### 3. Load all functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537794da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_julian(year,doy):\n",
    "    date = datetime.datetime(year, 1, 1) + datetime.timedelta(days=doy - 1)\n",
    "    return date.month, date.day\n",
    "# ----------------------------------------------------------------------\n",
    "def nasa2dly(dly_fp, dly_fn, wxpm_fp=None, hly=None, spinup=None):\n",
    "    '''\n",
    "    formats nasa power data to APEX .dly (and others)\n",
    "    \n",
    "    parameters:\n",
    "        dly_fp: directory path to where output weather files will be written\n",
    "        dly_fn: filename for output\n",
    "        wpxpm_fp (optional): fp to wxpm executable, wxpm-03082019, for monthly (wp1) generation\n",
    "            --> note: file must contain both wxpm.exe and wxpmrun.DAT\n",
    "        hly (optional): generate hly file\n",
    "            --> 'uda' = generate from daily data using uniform disaggregation\n",
    "            --> 'nasa' = generate directly from nasa hourly data\n",
    "        spinup (optional): duplicates first year of data 3x to account for model spinup time\n",
    "    ''' \n",
    "\n",
    "    # read data into df\n",
    "    dly_df = pd.read_csv(StringIO(dly_NASA), delimiter=',', skiprows=14)\n",
    "\n",
    "    # add columns MONTH and DAY\n",
    "    dly_df['MONTH'], dly_df['DAY'] = zip(*dly_df.apply(lambda row: convert_julian(int(row['YEAR']), int(row['DOY'])), axis=1))\n",
    "    \n",
    "    # set column names to match .dly\n",
    "    dly_colnames = {'T2M_MAX':'TMAX',\n",
    "                    'T2M_MIN':'TMIN',\n",
    "                    'PRECTOTCORR':'PRCP',\n",
    "                    'RH2M':'RH',\n",
    "                    'ALLSKY_SFC_SW_DWN':'SRAD',\n",
    "                    'WS10M':'WSPD'}\n",
    "    dly_df = dly_df.rename(columns=dly_colnames)\n",
    "    \n",
    "    # rearrange columns\n",
    "    dly_df = dly_df[['YEAR','MONTH','DAY','SRAD','TMAX','TMIN','PRCP','RH','WSPD']]\n",
    "    \n",
    "    # build path to .dly file\n",
    "    dly_path = os.path.join(dly_fp, dly_fn)\n",
    "\n",
    "    # write .dly file \n",
    "    with open(dly_path, 'w') as file:\n",
    "        for _, row in dly_df.iterrows():\n",
    "            file.write(f'{int(row['YEAR']):6d} {int(row['MONTH']):3d} {int(row['DAY']):3d} {float(row['SRAD']):5.1f} {float(row['TMAX']):5.1f} {float(row['TMIN']):5.1f} {float(row['PRCP']):5.1f} {float(row['RH']):5.1f} {float(row['WSPD']):5.1f}\\n')\n",
    "\n",
    "    \n",
    "    # generate wp1 file (if specified)\n",
    "    if wxpm_fp is not None:\n",
    "       dly2wp1(dly_fp, dly_fn, wxpm_fp)\n",
    "\n",
    "    # generate .hly file via equal disaggregation (if specified)\n",
    "    if hly == 'uda':\n",
    "        dly2hly(dly_fp, dly_fn)\n",
    "    else:\n",
    "        hly_fn = dly_fn.replace('.dly', '.hly')\n",
    "        nasa2hly(dly_fp, hly_fn)\n",
    "    \n",
    "    # add spinup time (if specified)\n",
    "    if spinup is not None:\n",
    "        add_spinup(dly_fp, dly_fn)\n",
    "        if hly is not None:\n",
    "            hly_fn = dly_fn.replace('.dly', '.hly')\n",
    "            add_spinup(dly_fp, hly_fn)\n",
    "# ----------------------------------------------------------------------\n",
    "def nasa2hly(hly_fp,hly_fn):\n",
    "    '''\n",
    "    converts .hly file to .nasa format\n",
    "    parameters:\n",
    "        hly_fp: path to .hly file\n",
    "        hly_fn: name of .hly file\n",
    "    '''\n",
    "    # read data into df\n",
    "    hly_df = pd.read_csv(StringIO(hly_NASA), delimiter=',', skiprows=9)\n",
    "    hly_colnames = {'YEAR':'YEAR',\n",
    "                    'MO':'MONTH',\n",
    "                    'DY':'DAY',\n",
    "                    'HR':'HOUR',\n",
    "                    'PRECTOTCORR':'RFDT'}\n",
    "    hly_df = hly_df.rename(columns=hly_colnames)\n",
    "\n",
    "    # convert to mm for APEX\n",
    "    hly_df['RFDT'] = hly_df['RFDT']/24\n",
    "    hly_df['RFDT'] = hly_df.groupby(['YEAR','MONTH','DAY'])['RFDT'].cumsum() # cumulative\n",
    "    \n",
    "    # adjust index for hourly\n",
    "    hly_df['HOUR'] = hly_df['HOUR'] + 1\n",
    "    \n",
    "    # build path to .dly file\n",
    "    hly_path = os.path.join(hly_fp, hly_fn)\n",
    "\n",
    "    # write .dly file \n",
    "    with open(hly_path, 'w') as file:\n",
    "            for _, row in hly_df.iterrows():\n",
    "                file.write(f'{int(row['YEAR']):4d} {int(row['MONTH']):3d} {int(row['DAY']):3d} {int(row['HOUR']):9d} {float(row['RFDT']):9.3f}\\n')\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "def dly2hly(dly_fp, dly_fn):\n",
    "    '''\n",
    "    generates .hly file from .dly file using uniform disaggregation\n",
    "\n",
    "    parameters:\n",
    "        dly_fp: path to .dly file\n",
    "        dly_fn: name of .dly file\n",
    "    '''\n",
    "\n",
    "    # set path to dly file\n",
    "    dly_path = os.path.join(dly_fp, dly_fn)\n",
    "\n",
    "    # read dly file into df\n",
    "    colspecs = [(0, 6), (7, 10), (11, 14), (15, 20), (21, 26), (27, 32), (33, 38), (39, 44), (45, 50)]\n",
    "    dly_df = pd.read_fwf(dly_path, colspecs=colspecs, header=None)\n",
    "    dly_colnames = ['YEAR','MONTH','DAY','SRAD','TMAX','TMIN','PRCP','RH','WSPD']\n",
    "    dly_df.columns = dly_colnames\n",
    "\n",
    "    # create hly df where each row is duplicated 24 times\n",
    "    hly_df = dly_df.loc[dly_df.index.repeat(24)].copy()\n",
    "\n",
    "    # add column for hour of the day\n",
    "    hly_df['HOUR'] = np.tile(np.arange(1,25), len(dly_df))\n",
    "\n",
    "    # create new column for hourly precip\n",
    "    hly_df['RFDT'] = hly_df['PRCP']/24\n",
    "    hly_df['RFDT'] = hly_df.groupby(['YEAR','MONTH','DAY'])['RFDT'].cumsum() # cumulative\n",
    "\n",
    "    # drop unncessary columns\n",
    "    hly_df_filtered = hly_df.drop(columns=['SRAD','TMAX','TMIN','PRCP','RH','WSPD'])\n",
    "\n",
    "    # build path to hly file\n",
    "    hly_fn = os.path.splitext(dly_fn)[0] + '.hly'\n",
    "    hly_path = os.path.join(dly_fp, hly_fn)\n",
    "\n",
    "    # format and write into hly file\n",
    "    with open(hly_path, 'w') as file:\n",
    "            for _, row in hly_df_filtered.iterrows():\n",
    "                file.write(f'{int(row['YEAR']):4d} {int(row['MONTH']):4d} {int(row['DAY']):4d} {int(row['HOUR']):10d} {float(row['RFDT']):10f}\\n')\n",
    "\n",
    "#----------------------------------------------------------------\n",
    "\n",
    "def dly2wp1(dly_fp, dly_fn, wxpm_fp):\n",
    "    \n",
    "    '''\n",
    "    converts .dly file to .wp1 using wxpm\n",
    "    \n",
    "    parameters:\n",
    "        dly_fp: path to file containing source .dly (and destination for wp1)\n",
    "        dly_fn: .dly filename\n",
    "        wxpm_fp: path to file containing wxpmrun.dat and wxpm.exe\n",
    "    '''\n",
    "    \n",
    "    # set file paths\n",
    "    src_dly = os.path.join(dly_fp, dly_fn)\n",
    "    wxpm_dly = os.path.join(wxpm_fp, dly_fn)\n",
    "    wxpm_run = os.path.join(wxpm_fp, 'wxpmrun.dat')\n",
    "    wxpm_exe = os.path.join(wxpm_fp, 'wxpm.exe')\n",
    "    wp1_fn = os.path.splitext(dly_fn)[0] + '.wp1'\n",
    "    out_wp1 = os.path.join(dly_fp, wp1_fn)\n",
    "\n",
    "    # copy DLY file into WXPM folder\n",
    "    shutil.copy(src_dly, wxpm_dly)\n",
    "\n",
    "    # update wxpmrun.dat\n",
    "    df = pd.read_csv(src_dly)\n",
    "    yr1 = df.iloc[:,0].min() # get start year of data\n",
    "    base_name = os.path.splitext(dly_fn)[0] # get name of dly file without extension\n",
    "    with open(wxpm_run, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    lines[0] = f\"{base_name} {yr1}\\n\"\n",
    "    with open(wxpm_run, 'w') as f:\n",
    "        f.writelines(lines)\n",
    "\n",
    "    # run wxpm.exe\n",
    "    subprocess.run([wxpm_exe], cwd=wxpm_fp)\n",
    "\n",
    "    # copy generated wp1 to dly folder\n",
    "    shutil.copy(os.path.join(wxpm_fp, wp1_fn), out_wp1)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "def add_spinup(fp,fn):\n",
    "    \n",
    "    '''\n",
    "    adds spinup time to .dly or .hly file by repeating the first year of data three times\n",
    "\n",
    "    warnings:\n",
    "    - duplicated years should be excluded from output analysis\n",
    "    - \"year\" column in duplicated years is modified based on their position in the dataframe\n",
    "        --> these values do not represent actual years - they are just labeled to ensure proper model execution\n",
    "    \n",
    "    parameters:\n",
    "        fp: path to weather file\n",
    "        fn: name of weather file\n",
    "    '''\n",
    "\n",
    "    file_path = os.path.join(fp, fn)\n",
    "\n",
    "    # read data in as df\n",
    "    # weather_df = pd.read_csv(file_path, header=None, sep='\\s+')\n",
    "    if file_path.split('.')[1] == 'dly':\n",
    "        colspecs = [(0, 6), (7, 10), (11, 14), (15, 20), (21, 26), (27, 32), (33, 38), (39, 44), (45, 50)]\n",
    "        weather_df = pd.read_fwf(file_path, colspecs=colspecs, header=None)\n",
    "        weather_df.columns =['YEAR','MONTH','DAY','SRAD','TMAX','TMIN','PRCP','RH','WSPD']\n",
    "        file_type = 'dly'\n",
    "    if file_path.split('.')[1] == 'hly':\n",
    "        colspecs = [(0, 4), (5, 8), (9, 12), (13, 22), (23, 32)]\n",
    "        weather_df = pd.read_fwf(file_path, colspecs=colspecs, header=None)\n",
    "        weather_df.columns =['YEAR','MONTH','DAY','HOUR','RFDT']\n",
    "        file_type = 'hly'\n",
    "\n",
    "    # get first year of data (column 1)\n",
    "    yr1 = weather_df.iloc[:,0].min()\n",
    "\n",
    "    # duplicate first year 3x, adjusting number of year\n",
    "    yr1_data = weather_df[weather_df.iloc[:,0] == yr1]\n",
    "    duplicated_data = pd.concat([yr1_data]*3, ignore_index=True)\n",
    "\n",
    "    # adjust year column for duplicated data\n",
    "    for i in range(3):\n",
    "        duplicated_data.iloc[i*len(yr1_data):(i+1)*len(yr1_data), 0] = yr1 - (3-i)\n",
    "\n",
    "\n",
    "    # add duplicated data to existing file\n",
    "    weather_df = pd.concat([duplicated_data, weather_df], ignore_index=True)\n",
    "\n",
    "    # write updated file\n",
    "    # new file name keeps the same name (and extension) but adds '_spinup'\n",
    "    spinup_fn = fn.split('.')[0] + '_spinup.' + fn.split('.')[1]\n",
    "    spinup_path = os.path.join(fp, spinup_fn)\n",
    "\n",
    "    # write file according to file extension\n",
    "    with open(spinup_path, 'w') as file:\n",
    "        for _, row in weather_df.iterrows():\n",
    "            if file_type == 'dly':\n",
    "                file.write(f'{int(row['YEAR']):6d} {int(row['MONTH']):3d} {int(row['DAY']):3d} {float(row['SRAD']):5.1f} {float(row['TMAX']):5.1f} {float(row['TMIN']):5.1f} {float(row['PRCP']):5.1f} {float(row['RH']):5.1f} {float(row['WSPD']):5.1f}\\n')\n",
    "            if file_type == 'hly':\n",
    "                file.write(f'{int(row['YEAR']):4d} {int(row['MONTH']):3d} {int(row['DAY']):3d} {int(row['HOUR']):9d} {float(row['RFDT']):9.3f}\\n')\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e48f79d",
   "metadata": {},
   "source": [
    "#### 4. Generate files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d27ce0c",
   "metadata": {},
   "source": [
    "##### APEX2DLY: Daily & More\n",
    "This function generates .dly files from NASA data downloaded using the API method above. You can also enter some optional arguments to generate accompanying monthly (.wp1) and hourly (.hly) files, either directly from NASA data or uniformly aggregated from the daily data, as well as add three years years of spinup time. <br><br>Note: The filepath for your .dly file should be where the rest of your APEX input and executable files are stored. <br><br>The optional functionalities can also be used independently (see blocks below for individual functions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb74b0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dly_fp = 'C:\\\\APEX\\\\apex1501-20241028\\\\test' # replace with folder path where file will be written\n",
    "dly_fn = 'test.dly' # replace with desired file name\n",
    "\n",
    "# optional (uncomment to use)\n",
    "#wxpm_fp = 'C:\\\\APEX\\\\wxpm-03082019\\\\' # edit to match path to wxpm folder for .wp1 generation\n",
    "#hly = 'uda' # generate hly file using uniform disaggregation ('uda') or directly from nasa data ('nasa')\n",
    "#spinup = 'y' # duplicate first year of data 3x to account for model spinup time\n",
    "\n",
    "nasa2dly(dly_fp, dly_fn) # adjust/add arguments as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afc6fe1",
   "metadata": {},
   "source": [
    "##### NASA2HLY: Hourly (from NASA)\n",
    "\n",
    "This function generates .hly files from NASA data downloaded using the API method above. See dly2hly for hourly data uniformly aggregated from daily NASA data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ca0b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "hly_fp = 'C:\\\\APEX\\\\apex1501-20241028\\\\test' # replace with folder path where file will be written\n",
    "hly_fn = 'test.hly' # replace with desired file name\n",
    "\n",
    "nasa2hly(hly_fp,hly_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e307a1da",
   "metadata": {},
   "source": [
    "##### DLY2HLY: Hourly (Uniformly Aggregated)\n",
    "This function generates .hly files, uniformly aggregated from an existing .dly file.\n",
    "<br> *note: hourly file with share the same name as the source .dly file (but with .hly extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d4c22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dly_fp = 'C:\\\\APEX\\\\apex1501-20241028\\\\test' # replace with folder path where source .dly exists\n",
    "dly_fn = 'test.dly' # replace with source .dly filename\n",
    "\n",
    "dly2hly(dly_fp, dly_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549e65fa",
   "metadata": {},
   "source": [
    "##### DLY2WP1: Monthly\n",
    "\n",
    "This function generates .wp1 files from an existing .dly file, using APEX's monthly weather file generation program, WXPM v.3020 (can be downloaded at https://epicapex.tamu.edu/software/). \n",
    "<br> *note: monthly file with share the same name as the source .dly file (but with .wp1 extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45454407",
   "metadata": {},
   "outputs": [],
   "source": [
    "dly_fp = 'C:\\\\APEX\\\\apex1501-20241028\\\\test' # replace with folder path where source .dly exists\n",
    "dly_fn = 'test.dly' # replace with source .dly filename\n",
    "wxpm_fp = 'C:\\\\APEX\\\\wxpm-03082019\\\\' # replace with path to wxpm folder\n",
    "\n",
    "dly2wp1(dly_fp, dly_fn, wxpm_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3a8b42",
   "metadata": {},
   "source": [
    "##### add_spinup: Spinup time\n",
    "\n",
    "This function adds spinup time to an existing .dly or .hly file by repeating the first year of data three times.\n",
    "<br> *warnings: <br> - duplicated years should be excluded from output analysis (first three years) <br> - \"year\" column in duplicated years is modified based on their position in the dataframe; these values do not represent actual years - they are just labeled to ensure proper model execution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556227a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = 'C:\\\\APEX\\\\apex1501-20241028\\\\test' # replace with folder path where source .dly or .hly exists\n",
    "fn = 'test.dly' # replace with source .dly or .hly filename\n",
    "\n",
    "add_spinup(fp,fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
